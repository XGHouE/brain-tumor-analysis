{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T11:33:19.210145Z","iopub.status.busy":"2025-03-01T11:33:19.209853Z","iopub.status.idle":"2025-03-01T11:33:19.550165Z","shell.execute_reply":"2025-03-01T11:33:19.549286Z","shell.execute_reply.started":"2025-03-01T11:33:19.210124Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import sys\n","import os\n","import math\n","import time\n","import pathlib\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.applications import EfficientNetV2L\n","from tensorflow.keras.applications import ResNet152V2\n","from tensorflow.keras.applications import Xception\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.applications import MobileNetV2\n","from sklearn.utils.class_weight import compute_class_weight\n","from tensorflow.keras.models import load_model\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, mean_absolute_error, mean_squared_error"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset paths"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T05:54:47.356113Z","iopub.status.busy":"2025-03-01T05:54:47.355783Z","iopub.status.idle":"2025-03-01T05:54:47.360456Z","shell.execute_reply":"2025-03-01T05:54:47.359517Z","shell.execute_reply.started":"2025-03-01T05:54:47.356084Z"},"trusted":true},"outputs":[],"source":["# Dataset paths\n","train_dir = pathlib.Path('/BrainTumorDataset/Training')\n","test_dir = pathlib.Path('/BrainTumorDataset/Testing')\n","\n","img_height = 224\n","img_width = 224\n","batch_size = 32\n","epochs = 30"]},{"cell_type":"markdown","metadata":{},"source":["# Data augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T05:54:49.71085Z","iopub.status.busy":"2025-03-01T05:54:49.710479Z","iopub.status.idle":"2025-03-01T05:54:56.32337Z","shell.execute_reply":"2025-03-01T05:54:56.322727Z","shell.execute_reply.started":"2025-03-01T05:54:49.710821Z"},"trusted":true},"outputs":[],"source":["# Dataset loading\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","    train_dir,\n","    validation_split=0.2,\n","    subset=\"training\",\n","    seed=123,\n","    image_size=(224, 224),\n","    batch_size=batch_size,\n","    shuffle=True,\n","    interpolation=\"bilinear\",\n","    label_mode=\"int\",\n",")\n","\n","# Get class names\n","class_names = train_ds.class_names\n","print(\"Classes in the dataset:\", class_names)\n","\n","# Normalize and apply data augmentation\n","normalization_layer = tf.keras.layers.Rescaling(1./255)\n","data_augmentation = tf.keras.Sequential([\n","    tf.keras.layers.RandomFlip(\"horizontal\"),\n","    tf.keras.layers.RandomRotation(0.2),\n","    tf.keras.layers.RandomZoom(0.2),\n","    tf.keras.layers.RandomContrast(0.2),\n","    tf.keras.layers.RandomTranslation(0.1, 0.1),\n","])\n","\n","train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n","train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n","\n","# Validation dataset\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","    train_dir,\n","    validation_split=0.2,\n","    subset=\"validation\",\n","    seed=123,\n","    image_size=(224, 224),\n","    batch_size=batch_size,\n",")\n","\n","val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n","\n","# Test dataset\n","test_ds = tf.keras.utils.image_dataset_from_directory(\n","    test_dir,\n","    image_size=(224, 224),\n","    batch_size=batch_size,\n",")\n","\n","test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"]},{"cell_type":"markdown","metadata":{},"source":["# Balancing using class weights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T05:54:56.32459Z","iopub.status.busy":"2025-03-01T05:54:56.324301Z","iopub.status.idle":"2025-03-01T05:56:07.520039Z","shell.execute_reply":"2025-03-01T05:56:07.519193Z","shell.execute_reply.started":"2025-03-01T05:54:56.324569Z"},"trusted":true},"outputs":[],"source":["def get_class_weights(train_ds, class_names):\n","    print(\"Calculating class weights...\")\n","    \n","    labels = []\n","    for image_batch, label_batch in train_ds:\n","        labels.append(label_batch.numpy())\n","\n","    labels = np.concatenate(labels)\n","    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n","\n","    class_weight_dict = {i: class_weights[i] for i in range(len(class_names))}\n","    print(\"Class weights calculated.\")\n","    return class_weight_dict\n","\n","class_weight_dict = get_class_weights(train_ds, class_names)"]},{"cell_type":"markdown","metadata":{},"source":["# Create and train model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T05:56:07.521819Z","iopub.status.busy":"2025-03-01T05:56:07.521556Z","iopub.status.idle":"2025-03-01T05:56:07.528904Z","shell.execute_reply":"2025-03-01T05:56:07.527989Z","shell.execute_reply.started":"2025-03-01T05:56:07.521798Z"},"trusted":true},"outputs":[],"source":["def create_and_train_model(base_model, model_name, train_ds, val_ds, test_ds, num_classes=4, learning_rate=0.0001, epochs=epochs, class_weight=None):\n","    for layer in base_model.layers[:10]:\n","        layer.trainable = False\n","\n","    x = layers.GlobalAveragePooling2D()(base_model.output)\n","    x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n","    x = layers.Dropout(0.4)(x)\n","    predictions = layers.Dense(num_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=base_model.inputs, outputs=predictions)\n","    model.compile(\n","        optimizer=Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999),\n","        loss=tf.losses.SparseCategoricalCrossentropy(),\n","        metrics=['accuracy']\n","    )\n","\n","    print(f\"\\nSummary of {model_name}:\")\n","    model.summary()\n","\n","    model_checkpoint = ModelCheckpoint(f'{model_name}.keras', monitor='val_loss', save_best_only=True)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)\n","\n","    start_time = time.time()\n","    history = model.fit(\n","        train_ds,\n","        shuffle=True,\n","        validation_data=val_ds,\n","        epochs=epochs,\n","        class_weight=class_weight,  \n","        callbacks=[model_checkpoint, reduce_lr]\n","    )\n","\n","    # End time tracking\n","    end_time = time.time()\n","    \n","    # Calculate computation time\n","    computation_time = end_time - start_time\n","\n","    print(f\"Model training took {computation_time:.2f} seconds.\")\n","\n","    print(f\"\\nEvaluating {model_name}...\")\n","    print(f\"\\nClass Weights used in training {model_name}: {class_weight}\")\n","    loss, accuracy = model.evaluate(test_ds)\n","    print('Loss:', loss)\n","    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n","    model.save(f'{model_name}.keras')\n","    evaluation = model.evaluate(test_ds)\n","\n","    return model, history, evaluation, computation_time"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T05:56:07.530382Z","iopub.status.busy":"2025-03-01T05:56:07.530124Z","iopub.status.idle":"2025-03-01T05:56:07.548298Z","shell.execute_reply":"2025-03-01T05:56:07.547456Z","shell.execute_reply.started":"2025-03-01T05:56:07.530364Z"},"trusted":true},"outputs":[],"source":["def evaluate_model(model, test_ds, model_name):\n","    y_true = []\n","    y_pred = []\n","    \n","    for images, labels in test_ds:\n","        predictions = model.predict(images)\n","        y_pred.extend(np.argmax(predictions, axis=1))\n","        y_true.extend(labels.numpy())\n","    \n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","    \n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","    f1 = f1_score(y_true, y_pred, average='weighted')\n","    mae = mean_absolute_error(y_true, y_pred)\n","    rmse = mean_squared_error(y_true, y_pred, squared=False)\n","    \n","    cm = confusion_matrix(y_true, y_pred)\n","    \n","    print(f\"\\nModel Evaluation Metrics for {model_name}:\")\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1 Score: {f1:.4f}\")\n","    print(f\"MAE: {mae:.4f}\")\n","    print(f\"RMSE: {rmse:.4f}\")\n","    \n","    plt.figure(figsize=(6, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(4), yticklabels=range(4))\n","    plt.xlabel('Predicted Label')\n","    plt.ylabel('True Label')\n","    plt.title(f'Confusion Matrix - {model_name}')\n","    plt.show()\n","    \n","    return accuracy, precision, recall, f1, mae, rmse, cm"]},{"cell_type":"markdown","metadata":{},"source":["# Train all models with 30 epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T05:56:07.549456Z","iopub.status.busy":"2025-03-01T05:56:07.549167Z","iopub.status.idle":"2025-03-01T05:56:26.683192Z","shell.execute_reply":"2025-03-01T05:56:26.682279Z","shell.execute_reply.started":"2025-03-01T05:56:07.549435Z"},"trusted":true},"outputs":[],"source":["# Define the base models\n","base_model1 = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","base_model2 = EfficientNetV2L(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","base_model3 = ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","base_model4 = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","base_model5 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","base_model6 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T05:56:26.684536Z","iopub.status.busy":"2025-03-01T05:56:26.684215Z","iopub.status.idle":"2025-03-01T11:30:19.23131Z","shell.execute_reply":"2025-03-01T11:30:19.230507Z","shell.execute_reply.started":"2025-03-01T05:56:26.684507Z"},"trusted":true},"outputs":[],"source":["model1, history1, evaluation1, time1 = create_and_train_model(base_model1, 'model1_inceptionv3_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n","model2, history2, evaluation2, time2 = create_and_train_model(base_model2, 'model2_efficientnetv2l_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n","model3, history3, evaluation3, time3 = create_and_train_model(base_model3, 'model3_resnet152v2_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n","model4, history4, evaluation4, time4 = create_and_train_model(base_model4, 'model4_xception_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n","model5, history5, evaluation5, time5 = create_and_train_model(base_model5, 'model5_vgg16_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n","model6, history6, evaluation6, time6 = create_and_train_model(base_model6, 'model6_mobilenetv2_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T11:32:09.737189Z","iopub.status.busy":"2025-03-01T11:32:09.736861Z","iopub.status.idle":"2025-03-01T11:32:10.727907Z","shell.execute_reply":"2025-03-01T11:32:10.726929Z","shell.execute_reply.started":"2025-03-01T11:32:09.737161Z"},"trusted":true},"outputs":[],"source":["# Define model names\n","model_names = [\n","    \"InceptionV3\", \"EfficientNetV2L\", \"ResNet152V2\",\n","    \"Xception\", \"VGG16\", \"MobileNetV2\"\n","]\n","\n","# Store histories in a list\n","histories = [history1, history2, history3, history4, history5, history6]\n","\n","# Plot Training Accuracy\n","plt.figure(figsize=(12, 6))\n","for i, history in enumerate(histories):\n","    plt.plot(history.history['accuracy'], label=f'{model_names[i]} Training')\n","plt.title('Training Accuracy over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid()\n","plt.show()\n","\n","# Plot Validation Accuracy\n","plt.figure(figsize=(12, 6))\n","for i, history in enumerate(histories):\n","    plt.plot(history.history['val_accuracy'], label=f'{model_names[i]} Validation')\n","plt.title('Validation Accuracy over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid()\n","plt.show()\n","\n","# Plot Training Loss\n","plt.figure(figsize=(12, 6))\n","for i, history in enumerate(histories):\n","    plt.plot(history.history['loss'], label=f'{model_names[i]} Training Loss')\n","plt.title('Training Loss over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid()\n","plt.show()\n","\n","# Plot Validation Loss\n","plt.figure(figsize=(12, 6))\n","for i, history in enumerate(histories):\n","    plt.plot(history.history['val_loss'], label=f'{model_names[i]} Validation Loss')\n","plt.title('Validation Loss over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T11:33:29.97059Z","iopub.status.busy":"2025-03-01T11:33:29.970075Z","iopub.status.idle":"2025-03-01T11:35:24.140369Z","shell.execute_reply":"2025-03-01T11:35:24.139496Z","shell.execute_reply.started":"2025-03-01T11:33:29.970563Z"},"trusted":true},"outputs":[],"source":["# After training models\n","evaluate_model(model1, test_ds, 'model1_inceptionv3_class_weights')\n","evaluate_model(model2, test_ds, 'model2_efficientnetv2l_class_weights')\n","evaluate_model(model3, test_ds, 'model3_resnet152v2_class_weights')\n","evaluate_model(model4, test_ds, 'model4_xception_class_weights')\n","evaluate_model(model5, test_ds, 'model5_vgg16_class_weights')\n","evaluate_model(model6, test_ds, 'model6_mobilenetv2_class_weights')"]},{"cell_type":"markdown","metadata":{},"source":["# Load models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T11:43:33.999043Z","iopub.status.busy":"2025-03-01T11:43:33.998679Z","iopub.status.idle":"2025-03-01T11:44:12.116541Z","shell.execute_reply":"2025-03-01T11:44:12.115756Z","shell.execute_reply.started":"2025-03-01T11:43:33.999018Z"},"trusted":true},"outputs":[],"source":["model1 = load_model('/kaggle/working/model1_inceptionv3_class_weights.keras')\n","model2 = load_model('/kaggle/working/model2_efficientnetv2l_class_weights.keras')\n","model3 = load_model('/kaggle/working/model3_resnet152v2_class_weights.keras')\n","model4 = load_model('/kaggle/working/model4_xception_class_weights.keras')\n","model5 = load_model('/kaggle/working/model5_vgg16_class_weights.keras')\n","model6 = load_model('/kaggle/working/model6_mobilenetv2_class_weights.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T11:44:12.11831Z","iopub.status.busy":"2025-03-01T11:44:12.117968Z","iopub.status.idle":"2025-03-01T11:44:12.12247Z","shell.execute_reply":"2025-03-01T11:44:12.121729Z","shell.execute_reply.started":"2025-03-01T11:44:12.118274Z"},"trusted":true},"outputs":[],"source":["# Define ensembles\n","ensemble1 = [model2, model4, model3]\n","ensemble2 = [model1, model2, model4]\n","ensemble3 = [model2, model3, model6]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T11:45:30.038052Z","iopub.status.busy":"2025-03-01T11:45:30.037756Z","iopub.status.idle":"2025-03-01T11:45:30.042958Z","shell.execute_reply":"2025-03-01T11:45:30.042053Z","shell.execute_reply.started":"2025-03-01T11:45:30.038031Z"},"trusted":true},"outputs":[],"source":["def ensemble_predict(models, test_ds):\n","    all_predictions = []\n","    y_true = []\n","\n","    for images, labels in test_ds:\n","        y_true.extend(labels.numpy())  \n","        preds = [model.predict(images, verbose=0) for model in models]\n","        all_predictions.append(np.mean(preds, axis=0)) \n","\n","    avg_predictions = np.vstack(all_predictions)  \n","    final_predictions = np.argmax(avg_predictions, axis=1) \n","    return np.array(y_true), final_predictions, avg_predictions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-01T11:45:32.573793Z","iopub.status.busy":"2025-03-01T11:45:32.573478Z","iopub.status.idle":"2025-03-01T11:45:32.58127Z","shell.execute_reply":"2025-03-01T11:45:32.580445Z","shell.execute_reply.started":"2025-03-01T11:45:32.573768Z"},"trusted":true},"outputs":[],"source":["# Function to evaluate ensemble and save results\n","def evaluate_and_save_ensemble(models, test_ds, model_name):\n","    y_true, y_pred, avg_probs = ensemble_predict(models, test_ds)\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, average='macro')\n","    recall = recall_score(y_true, y_pred, average='macro')\n","    f1 = f1_score(y_true, y_pred, average='macro')\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    sensitivity = np.mean(np.diag(cm) / np.sum(cm, axis=1))  \n","    specificity = np.mean(np.diag(cm) / np.sum(cm, axis=0)) \n","\n","    # Additional metrics\n","    mae = mean_absolute_error(y_true, y_pred)\n","    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n","\n","    # Print evaluation metrics\n","    print(f\"\\n=== Model Evaluation Metrics for {model_name} ===\")\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1 Score: {f1:.4f}\")\n","    print(f\"Sensitivity: {sensitivity:.4f}\")\n","    print(f\"Specificity: {specificity:.4f}\")\n","    print(f\"MAE: {mae:.4f}\")\n","    print(f\"RMSE: {rmse:.4f}\")\n","\n","    # Save results\n","    with open(f'{model_name}_results.pkl', 'wb') as f:\n","        pickle.dump({'y_true': y_true, 'y_pred': y_pred, 'avg_probs': avg_probs}, f)\n","    \n","    print(f\"Ensemble '{model_name}' results saved successfully!\")\n","\n","    # Plot confusion matrix\n","    plt.figure(figsize=(6, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(4), yticklabels=range(4))\n","    plt.xlabel('Predicted Label')\n","    plt.ylabel('True Label')\n","    plt.title(f'Confusion Matrix - {model_name}')\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2025-03-01T11:45:36.594234Z","iopub.status.busy":"2025-03-01T11:45:36.593945Z","iopub.status.idle":"2025-03-01T11:48:16.207336Z","shell.execute_reply":"2025-03-01T11:48:16.206624Z","shell.execute_reply.started":"2025-03-01T11:45:36.594211Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["# Run evaluation for all ensembles\n","evaluate_and_save_ensemble(ensemble1, test_ds, \"ensemble1\")\n","evaluate_and_save_ensemble(ensemble2, test_ds, \"ensemble2\")\n","evaluate_and_save_ensemble(ensemble3, test_ds, \"ensemble3\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-02-28T14:40:16.349501Z","iopub.status.busy":"2025-02-28T14:40:16.349149Z","iopub.status.idle":"2025-02-28T14:40:16.850661Z","shell.execute_reply":"2025-02-28T14:40:16.849924Z","shell.execute_reply.started":"2025-02-28T14:40:16.349471Z"},"trusted":true},"outputs":[],"source":["ensembles = [\"Ensemble 1\", \"Ensemble 2\", \"Ensemble 3\"]\n","accuracy = [0.9947, 0.9924, 0.9908]\n","precision = [0.9945, 0.9920, 0.9904]\n","recall = [0.9946, 0.9921, 0.9905]\n","f1_score = [0.9945, 0.9921, 0.9904]\n","sensitivity = [0.9946, 0.9921, 0.9905]\n","specificity = [0.9945, 0.9920, 0.9904]\n","mae = [0.0076, 0.0137, 0.0130]\n","rmse = [0.1172, 0.1747, 0.1487]\n","\n","\n","colors = [\"#203f85\", \"#1eb4cb\", \"#fdf6de\", \"#f03c29\", \"#fbd022\"]\n","\n","\n","plt.figure(figsize=(8, 5))\n","plt.bar(ensembles, accuracy, color=colors[1])\n","plt.xlabel(\"Ensemble Models\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Accuracy Comparison of Ensemble Models\")\n","plt.ylim(0.98, 1.0) \n","for i, v in enumerate(accuracy):\n","    plt.text(i, v, f\"{v:.4f}\", ha='center', va='bottom', fontsize=12, color='black')\n","plt.show()\n","\n","\n","metrics = [precision, recall, f1_score]\n","labels = [\"Precision\", \"Recall\", \"F1 Score\"]\n","metric_colors = [colors[0], colors[3], colors[4]] \n","\n","plt.figure(figsize=(8, 5))\n","bar_width = 0.25\n","x = np.arange(len(ensembles))\n","\n","for i, metric in enumerate(metrics):\n","    plt.bar(x + i * bar_width, metric, width=bar_width, label=labels[i], color=metric_colors[i])\n","\n","plt.xlabel(\"Ensemble Models\")\n","plt.ylabel(\"Score\")\n","plt.title(\"Precision, Recall, and F1 Score Comparison\")\n","plt.xticks(x + bar_width, ensembles)\n","plt.legend()\n","plt.ylim(0.98, 1.0)\n","plt.show()\n","\n","\n","plt.figure(figsize=(8, 5))\n","bar_width = 0.25\n","x = np.arange(len(ensembles))\n","\n","plt.bar(x, mae, width=bar_width, label=\"MAE\", color=colors[3]) \n","plt.bar(x + bar_width, rmse, width=bar_width, label=\"RMSE\", color=colors[1]) \n","\n","plt.xlabel(\"Ensemble Models\")\n","plt.ylabel(\"Error\")\n","plt.title(\"MAE and RMSE Comparison\")\n","plt.xticks(x + bar_width / 2, ensembles)\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":1608934,"sourceId":2645886,"sourceType":"datasetVersion"},{"modelId":242991,"modelInstanceId":221210,"sourceId":258804,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30886,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
