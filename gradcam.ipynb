{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradcam(model, img_tensor, target_layer_name = \"conv5_block3_out\")\n",
    "    \n",
    "    target_layer = model.get_layer(target_layer_name)\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs],\n",
    "        [target_layer.output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_tensor)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        loss = predictions[:, pred_index]\n",
    "    \n",
    "    # Compute gradients of the loss with respect to the target layer outputs.\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    \n",
    "    # Global average pooling on the gradients to obtain weights.\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    conv_outputs = conv_outputs[0]\n",
    "    # Compute the weighted sum of feature maps.\n",
    "    heatmap = tf.reduce_sum(conv_outputs * pooled_grads, axis=-1)\n",
    "    \n",
    "    # Apply ReLU to discard negative contributions and normalize.\n",
    "    heatmap = tf.nn.relu(heatmap)\n",
    "    heatmap = heatmap / (tf.reduce_max(heatmap) + 1e-8)\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer_name = \"conv5_block3_out\"\n",
    "#img_tensor as preprocessed shit\n",
    "#resnet_model as the .keras file\n",
    "heatmap = compute_gradcam(resnet_model, img_tensor, target_layer_name)\n",
    "\n",
    "# Upsample the heatmap to match the UNet bottleneck size.\n",
    "# For a 256x256 UNet input, after four poolings the bottleneck is about 16x16.\n",
    "heatmap = tf.expand_dims(heatmap, axis=-1)  # Shape: (H, W, 1)\n",
    "upsampled_heatmap = tf.image.resize(heatmap, (16, 16), method='bilinear')\n",
    "upsampled_heatmap = tf.squeeze(upsampled_heatmap)  # Now shape is (16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "CHANNEL = 1\n",
    "CLASSES = 1\n",
    "def unet(input_size = (SIZE, SIZE, CHANNEL), num_classes = CLASSES, attn_map = None):\n",
    "    inputs = keras.layers.Input(input_size)\n",
    "    # Encoding (Downsampling)\n",
    "    c1 = keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    if attn_map is not None:\n",
    "        attn = tf.reshape(attn_map, (1, c5.shape[1], c5.shape[2], 1))\n",
    "        c5 = keras.layers.multiply([c5, attn])\n",
    "\n",
    "    # Decoding (Upsampling)\n",
    "    u6 = keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = keras.layers.concatenate([u6, c4])\n",
    "    c6 = keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = keras.layers.concatenate([u7, c3])\n",
    "    c7 = keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = keras.layers.concatenate([u8, c2])\n",
    "    c8 = keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = keras.layers.concatenate([u9, c1], axis=3)\n",
    "    c9 = keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = keras.layers.Conv2D(num_classes, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_with_attention = unet(\n",
    "    input_size=(SIZE, SIZE, CHANNEL), \n",
    "    num_classes=CLASSES, \n",
    "    attn_map=upsampled_heatmap\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
