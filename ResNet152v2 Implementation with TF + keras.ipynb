{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:33:19.210145Z",
          "iopub.status.busy": "2025-03-01T11:33:19.209853Z",
          "iopub.status.idle": "2025-03-01T11:33:19.550165Z",
          "shell.execute_reply": "2025-03-01T11:33:19.549286Z",
          "shell.execute_reply.started": "2025-03-01T11:33:19.210124Z"
        },
        "id": "2lfd1iJcx2YX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import pathlib\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "# There are other models we can use...\n",
        "# from tensorflow.keras.applications import InceptionV3\n",
        "# from tensorflow.keras.applications import EfficientNetV2L\n",
        "# from tensorflow.keras.applications import Xception\n",
        "# from tensorflow.keras.applications import VGG16\n",
        "# from tensorflow.keras.applications import MobileNetV2\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N--n_7q7x2YY"
      },
      "source": [
        "# Dataset paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-01T05:54:47.356113Z",
          "iopub.status.busy": "2025-03-01T05:54:47.355783Z",
          "iopub.status.idle": "2025-03-01T05:54:47.360456Z",
          "shell.execute_reply": "2025-03-01T05:54:47.359517Z",
          "shell.execute_reply.started": "2025-03-01T05:54:47.356084Z"
        },
        "id": "HbkRcHfVx2YZ",
        "outputId": "51b903fb-941b-4f37-db87-27523c447a1a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dataset paths\n",
        "train_dir = pathlib.Path('BrainTumorDataset/Training')\n",
        "test_dir = pathlib.Path('BrainTumorDataset/Testing')\n",
        "\n",
        "img_height = 512\n",
        "img_width = 512\n",
        "batch_size = 16\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pYGXcpJx2YZ"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-01T05:54:49.71085Z",
          "iopub.status.busy": "2025-03-01T05:54:49.710479Z",
          "iopub.status.idle": "2025-03-01T05:54:56.32337Z",
          "shell.execute_reply": "2025-03-01T05:54:56.322727Z",
          "shell.execute_reply.started": "2025-03-01T05:54:49.710821Z"
        },
        "id": "9D1SU9w6x2YZ",
        "outputId": "f06b82b4-bdf4-41da-9e11-d852b5a421e9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2442 files belonging to 4 classes.\n",
            "Using 1954 files for training.\n",
            "Classes in the dataset: ['1', '2', '3', 'notumor']\n",
            "Found 2442 files belonging to 4 classes.\n",
            "Using 488 files for validation.\n",
            "Found 2133 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Dataset loading\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(512, 512),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    interpolation=\"bilinear\",\n",
        "    label_mode=\"int\",\n",
        ")\n",
        "\n",
        "# Get class names\n",
        "class_names = train_ds.class_names\n",
        "print(\"Classes in the dataset:\", class_names)\n",
        "\n",
        "# Normalize and apply data augmentation\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2),\n",
        "    tf.keras.layers.RandomContrast(0.2),\n",
        "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
        "])\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "# Validation dataset\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(512, 512),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Test dataset\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=(512, 512),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BptN1X6Hx2Ya"
      },
      "source": [
        "# Balancing using class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-01T05:54:56.32459Z",
          "iopub.status.busy": "2025-03-01T05:54:56.324301Z",
          "iopub.status.idle": "2025-03-01T05:56:07.520039Z",
          "shell.execute_reply": "2025-03-01T05:56:07.519193Z",
          "shell.execute_reply.started": "2025-03-01T05:54:56.324569Z"
        },
        "id": "6E7O9Gdfx2Ya",
        "outputId": "6ebc570e-1625-49d5-a7fb-53694311f8bd",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating class weights...\n",
            "Class weights calculated.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-03 16:33:35.447282: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        }
      ],
      "source": [
        "def get_class_weights(train_ds, class_names):\n",
        "    print(\"Calculating class weights...\")\n",
        "\n",
        "    labels = []\n",
        "    for image_batch, label_batch in train_ds:\n",
        "        labels.append(label_batch.numpy())\n",
        "\n",
        "    labels = np.concatenate(labels)\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "\n",
        "    class_weight_dict = {i: class_weights[i] for i in range(len(class_names))}\n",
        "    print(\"Class weights calculated.\")\n",
        "    return class_weight_dict\n",
        "\n",
        "class_weight_dict = get_class_weights(train_ds, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:07.521819Z",
          "iopub.status.busy": "2025-03-01T05:56:07.521556Z",
          "iopub.status.idle": "2025-03-01T05:56:07.528904Z",
          "shell.execute_reply": "2025-03-01T05:56:07.527989Z",
          "shell.execute_reply.started": "2025-03-01T05:56:07.521798Z"
        },
        "id": "UyOCDnqbx2Ya",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def create_and_train_model(base_model, model_name, train_ds, val_ds, test_ds, num_classes=4, learning_rate=0.0001, epochs=epochs, class_weight=None):\n",
        "    for layer in base_model.layers[:10]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999),\n",
        "        loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(f\"\\nSummary of {model_name}:\")\n",
        "    model.summary()\n",
        "\n",
        "    model_checkpoint = ModelCheckpoint(f'{model_name}.keras', monitor='val_loss', save_best_only=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        shuffle=True,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs,\n",
        "        class_weight=class_weight,\n",
        "        callbacks=[model_checkpoint, reduce_lr]\n",
        "    )\n",
        "\n",
        "    # End time tracking\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate computation time\n",
        "    computation_time = end_time - start_time\n",
        "\n",
        "    print(f\"Model training took {computation_time:.2f} seconds.\")\n",
        "\n",
        "    print(f\"\\nEvaluating {model_name}...\")\n",
        "    print(f\"\\nClass Weights used in training {model_name}: {class_weight}\")\n",
        "    loss, accuracy = model.evaluate(test_ds)\n",
        "    print('Loss:', loss)\n",
        "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "    model.save(f'{model_name}.keras')\n",
        "    evaluation = model.evaluate(test_ds)\n",
        "\n",
        "    return model, history, evaluation, computation_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:07.530382Z",
          "iopub.status.busy": "2025-03-01T05:56:07.530124Z",
          "iopub.status.idle": "2025-03-01T05:56:07.548298Z",
          "shell.execute_reply": "2025-03-01T05:56:07.547456Z",
          "shell.execute_reply.started": "2025-03-01T05:56:07.530364Z"
        },
        "id": "ZflrHDiwx2Yb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_ds, model_name):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for images, labels in test_ds:\n",
        "        predictions = model.predict(images)\n",
        "        y_pred.extend(np.argmax(predictions, axis=1))\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = mean_squared_error(y_true, y_pred)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\nModel Evaluation Metrics for {model_name}:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(4), yticklabels=range(4))\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "    return accuracy, precision, recall, f1, mae, rmse, cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRWiAypxx2Yb"
      },
      "source": [
        "# Train all models with 30 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:07.549456Z",
          "iopub.status.busy": "2025-03-01T05:56:07.549167Z",
          "iopub.status.idle": "2025-03-01T05:56:26.683192Z",
          "shell.execute_reply": "2025-03-01T05:56:26.682279Z",
          "shell.execute_reply.started": "2025-03-01T05:56:07.549435Z"
        },
        "id": "rEczdOccx2Yb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the model(s)\n",
        "base_model3 = ResNet152V2(weights='imagenet', include_top=False, input_shape=(512, 512, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:26.684536Z",
          "iopub.status.busy": "2025-03-01T05:56:26.684215Z",
          "iopub.status.idle": "2025-03-01T11:30:19.23131Z",
          "shell.execute_reply": "2025-03-01T11:30:19.230507Z",
          "shell.execute_reply.started": "2025-03-01T05:56:26.684507Z"
        },
        "id": "_2lpTe-7x2Yb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(train_ds)\n",
        "model3, history3, evaluation3, time3 = create_and_train_model(base_model3, 'model3_resnet152v2_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:32:09.737189Z",
          "iopub.status.busy": "2025-03-01T11:32:09.736861Z",
          "iopub.status.idle": "2025-03-01T11:32:10.727907Z",
          "shell.execute_reply": "2025-03-01T11:32:10.726929Z",
          "shell.execute_reply.started": "2025-03-01T11:32:09.737161Z"
        },
        "id": "F-JNT8Rpx2Yb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define model names\n",
        "model_names = [\"ResNet152V2\"]\n",
        "\n",
        "# Store histories in a list\n",
        "histories = [history3]\n",
        "\n",
        "# Plot Training and Validation Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['accuracy'], label=f'{model_names[i]} Training')\n",
        "    plt.plot(history.history['val_accuracy'], label=f'{model_names[i]} Validation')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot Training and Validation Loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['loss'], label=f'{model_names[i]} Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label=f'{model_names[i]} Validation Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1AeNDvpmbHhOnHQCHb8ytiQi08uvrVKRx\n",
            "From (redirected): https://drive.google.com/uc?id=1AeNDvpmbHhOnHQCHb8ytiQi08uvrVKRx&confirm=t&uuid=38d01b8d-dbcb-4d7a-a9b1-bfd9f8c72d21\n",
            "To: /Users/ahmedalsunbati/Documents/GitHub/brain-tumor-analysis/ResNet152.keras\n",
            "100%|██████████| 714M/714M [00:30<00:00, 23.3MB/s] \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'ResNet152.keras'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "file_id = \"1AeNDvpmbHhOnHQCHb8ytiQi08uvrVKRx\"\n",
        "output_path = \"ResNet152.keras\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model_path = \"ResNet152.keras\"  # Update the path if needed\n",
        "model = keras.models.load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:33:29.97059Z",
          "iopub.status.busy": "2025-03-01T11:33:29.970075Z",
          "iopub.status.idle": "2025-03-01T11:35:24.140369Z",
          "shell.execute_reply": "2025-03-01T11:35:24.139496Z",
          "shell.execute_reply.started": "2025-03-01T11:33:29.970563Z"
        },
        "id": "7yV7nYK0x2Yc",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1741037682.358202 1414855 service.cc:148] XLA service 0x2ff4be7a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1741037682.358431 1414855 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
            "2025-03-03 16:34:42.591360: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1741037684.391210 1414855 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 42s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 36s/step\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#After training model(s)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m evaluate_model(model, test_ds, \u001b[39m'\u001b[39m\u001b[39mResNet152V2\u001b[39m\u001b[39m'\u001b[39m)\n",
            "Cell \u001b[0;32mIn[8], line 6\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_ds, model_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m y_pred \u001b[39m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m test_ds:\n\u001b[0;32m----> 6\u001b[0m     predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(images)\n\u001b[1;32m      7\u001b[0m     y_pred\u001b[39m.\u001b[39mextend(np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m      8\u001b[0m     y_true\u001b[39m.\u001b[39mextend(labels\u001b[39m.\u001b[39mnumpy())\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:562\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    560\u001b[0m callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m    561\u001b[0m data \u001b[39m=\u001b[39m get_data(iterator)\n\u001b[0;32m--> 562\u001b[0m batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_function(data)\n\u001b[1;32m    563\u001b[0m outputs \u001b[39m=\u001b[39m append_to_outputs(batch_outputs, outputs)\n\u001b[1;32m    564\u001b[0m callbacks\u001b[39m.\u001b[39mon_predict_batch_end(step, {\u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: batch_outputs})\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function\u001b[39m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_flat(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m   1684\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1685\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   1686\u001b[0m       inputs\u001b[39m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1687\u001b[0m       attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m   1688\u001b[0m       ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1689\u001b[0m   )\n\u001b[1;32m   1690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#After training model(s)\n",
        "evaluate_model(model, test_ds, 'ResNet152V2')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 1608934,
          "sourceId": 2645886,
          "sourceType": "datasetVersion"
        },
        {
          "modelId": 242991,
          "modelInstanceId": 221210,
          "sourceId": 258804,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30886,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
