{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:33:19.210145Z",
          "iopub.status.busy": "2025-03-01T11:33:19.209853Z",
          "iopub.status.idle": "2025-03-01T11:33:19.550165Z",
          "shell.execute_reply": "2025-03-01T11:33:19.549286Z",
          "shell.execute_reply.started": "2025-03-01T11:33:19.210124Z"
        },
        "id": "2lfd1iJcx2YX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import pathlib\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "# There are other models we can use...\n",
        "# from tensorflow.keras.applications import InceptionV3\n",
        "# from tensorflow.keras.applications import EfficientNetV2L\n",
        "# from tensorflow.keras.applications import Xception\n",
        "# from tensorflow.keras.applications import VGG16\n",
        "# from tensorflow.keras.applications import MobileNetV2\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N--n_7q7x2YY"
      },
      "source": [
        "# Dataset paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-01T05:54:47.356113Z",
          "iopub.status.busy": "2025-03-01T05:54:47.355783Z",
          "iopub.status.idle": "2025-03-01T05:54:47.360456Z",
          "shell.execute_reply": "2025-03-01T05:54:47.359517Z",
          "shell.execute_reply.started": "2025-03-01T05:54:47.356084Z"
        },
        "id": "HbkRcHfVx2YZ",
        "outputId": "51b903fb-941b-4f37-db87-27523c447a1a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dataset paths\n",
        "train_dir = pathlib.Path('BrainTumorDataset/Training')\n",
        "test_dir = pathlib.Path('BrainTumorDataset/Testing')\n",
        "\n",
        "img_height = 512\n",
        "img_width = 512\n",
        "batch_size = 16\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pYGXcpJx2YZ"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-01T05:54:49.71085Z",
          "iopub.status.busy": "2025-03-01T05:54:49.710479Z",
          "iopub.status.idle": "2025-03-01T05:54:56.32337Z",
          "shell.execute_reply": "2025-03-01T05:54:56.322727Z",
          "shell.execute_reply.started": "2025-03-01T05:54:49.710821Z"
        },
        "id": "9D1SU9w6x2YZ",
        "outputId": "f06b82b4-bdf4-41da-9e11-d852b5a421e9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2442 files belonging to 4 classes.\n",
            "Using 1954 files for training.\n",
            "Classes in the dataset: ['1', '2', '3', 'notumor']\n",
            "Found 2442 files belonging to 4 classes.\n",
            "Using 488 files for validation.\n",
            "Found 2133 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Dataset loading\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(512, 512),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    interpolation=\"bilinear\",\n",
        "    label_mode=\"int\",\n",
        ")\n",
        "\n",
        "# Get class names\n",
        "class_names = train_ds.class_names\n",
        "print(\"Classes in the dataset:\", class_names)\n",
        "\n",
        "# Normalize and apply data augmentation\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2),\n",
        "    tf.keras.layers.RandomContrast(0.2),\n",
        "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
        "])\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "# Validation dataset\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(512, 512),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Test dataset\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=(512, 512),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BptN1X6Hx2Ya"
      },
      "source": [
        "# Balancing using class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-01T05:54:56.32459Z",
          "iopub.status.busy": "2025-03-01T05:54:56.324301Z",
          "iopub.status.idle": "2025-03-01T05:56:07.520039Z",
          "shell.execute_reply": "2025-03-01T05:56:07.519193Z",
          "shell.execute_reply.started": "2025-03-01T05:54:56.324569Z"
        },
        "id": "6E7O9Gdfx2Ya",
        "outputId": "6ebc570e-1625-49d5-a7fb-53694311f8bd",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating class weights...\n",
            "Class weights calculated.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-03 16:33:35.447282: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        }
      ],
      "source": [
        "def get_class_weights(train_ds, class_names):\n",
        "    print(\"Calculating class weights...\")\n",
        "\n",
        "    labels = []\n",
        "    for image_batch, label_batch in train_ds:\n",
        "        labels.append(label_batch.numpy())\n",
        "\n",
        "    labels = np.concatenate(labels)\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "\n",
        "    class_weight_dict = {i: class_weights[i] for i in range(len(class_names))}\n",
        "    print(\"Class weights calculated.\")\n",
        "    return class_weight_dict\n",
        "\n",
        "class_weight_dict = get_class_weights(train_ds, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:07.521819Z",
          "iopub.status.busy": "2025-03-01T05:56:07.521556Z",
          "iopub.status.idle": "2025-03-01T05:56:07.528904Z",
          "shell.execute_reply": "2025-03-01T05:56:07.527989Z",
          "shell.execute_reply.started": "2025-03-01T05:56:07.521798Z"
        },
        "id": "UyOCDnqbx2Ya",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def create_and_train_model(base_model, model_name, train_ds, val_ds, test_ds, num_classes=4, learning_rate=0.0001, epochs=epochs, class_weight=None):\n",
        "    for layer in base_model.layers[:10]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999),\n",
        "        loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(f\"\\nSummary of {model_name}:\")\n",
        "    model.summary()\n",
        "\n",
        "    model_checkpoint = ModelCheckpoint(f'{model_name}.keras', monitor='val_loss', save_best_only=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        shuffle=True,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs,\n",
        "        class_weight=class_weight,\n",
        "        callbacks=[model_checkpoint, reduce_lr]\n",
        "    )\n",
        "\n",
        "    # End time tracking\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate computation time\n",
        "    computation_time = end_time - start_time\n",
        "\n",
        "    print(f\"Model training took {computation_time:.2f} seconds.\")\n",
        "\n",
        "    print(f\"\\nEvaluating {model_name}...\")\n",
        "    print(f\"\\nClass Weights used in training {model_name}: {class_weight}\")\n",
        "    loss, accuracy = model.evaluate(test_ds)\n",
        "    print('Loss:', loss)\n",
        "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "    model.save(f'{model_name}.keras')\n",
        "    evaluation = model.evaluate(test_ds)\n",
        "\n",
        "    return model, history, evaluation, computation_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:07.530382Z",
          "iopub.status.busy": "2025-03-01T05:56:07.530124Z",
          "iopub.status.idle": "2025-03-01T05:56:07.548298Z",
          "shell.execute_reply": "2025-03-01T05:56:07.547456Z",
          "shell.execute_reply.started": "2025-03-01T05:56:07.530364Z"
        },
        "id": "ZflrHDiwx2Yb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_ds, model_name):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for images, labels in test_ds:\n",
        "        predictions = model.predict(images)\n",
        "        y_pred.extend(np.argmax(predictions, axis=1))\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = mean_squared_error(y_true, y_pred)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\nModel Evaluation Metrics for {model_name}:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(4), yticklabels=range(4))\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "    return accuracy, precision, recall, f1, mae, rmse, cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRWiAypxx2Yb"
      },
      "source": [
        "# Train all models with 30 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:07.549456Z",
          "iopub.status.busy": "2025-03-01T05:56:07.549167Z",
          "iopub.status.idle": "2025-03-01T05:56:26.683192Z",
          "shell.execute_reply": "2025-03-01T05:56:26.682279Z",
          "shell.execute_reply.started": "2025-03-01T05:56:07.549435Z"
        },
        "id": "rEczdOccx2Yb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the model(s)\n",
        "base_model3 = ResNet152V2(weights='imagenet', include_top=False, input_shape=(512, 512, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:26.684536Z",
          "iopub.status.busy": "2025-03-01T05:56:26.684215Z",
          "iopub.status.idle": "2025-03-01T11:30:19.23131Z",
          "shell.execute_reply": "2025-03-01T11:30:19.230507Z",
          "shell.execute_reply.started": "2025-03-01T05:56:26.684507Z"
        },
        "id": "_2lpTe-7x2Yb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(train_ds)\n",
        "model3, history3, evaluation3, time3 = create_and_train_model(base_model3, 'model3_resnet152v2_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:32:09.737189Z",
          "iopub.status.busy": "2025-03-01T11:32:09.736861Z",
          "iopub.status.idle": "2025-03-01T11:32:10.727907Z",
          "shell.execute_reply": "2025-03-01T11:32:10.726929Z",
          "shell.execute_reply.started": "2025-03-01T11:32:09.737161Z"
        },
        "id": "F-JNT8Rpx2Yb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define model names\n",
        "model_names = [\"ResNet152V2\"]\n",
        "\n",
        "# Store histories in a list\n",
        "histories = [history3]\n",
        "\n",
        "# Plot Training and Validation Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['accuracy'], label=f'{model_names[i]} Training')\n",
        "    plt.plot(history.history['val_accuracy'], label=f'{model_names[i]} Validation')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot Training and Validation Loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['loss'], label=f'{model_names[i]} Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label=f'{model_names[i]} Validation Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1AeNDvpmbHhOnHQCHb8ytiQi08uvrVKRx\n",
            "From (redirected): https://drive.google.com/uc?id=1AeNDvpmbHhOnHQCHb8ytiQi08uvrVKRx&confirm=t&uuid=38d01b8d-dbcb-4d7a-a9b1-bfd9f8c72d21\n",
            "To: /Users/ahmedalsunbati/Documents/GitHub/brain-tumor-analysis/ResNet152.keras\n",
            "100%|██████████| 714M/714M [00:30<00:00, 23.3MB/s] \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'ResNet152.keras'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "file_id = \"1AeNDvpmbHhOnHQCHb8ytiQi08uvrVKRx\"\n",
        "output_path = \"ResNet152.keras\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model_path = \"ResNet152.keras\"  # Update the path if needed\n",
        "model = keras.models.load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:33:29.97059Z",
          "iopub.status.busy": "2025-03-01T11:33:29.970075Z",
          "iopub.status.idle": "2025-03-01T11:35:24.140369Z",
          "shell.execute_reply": "2025-03-01T11:35:24.139496Z",
          "shell.execute_reply.started": "2025-03-01T11:33:29.970563Z"
        },
        "id": "7yV7nYK0x2Yc",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1741037682.358202 1414855 service.cc:148] XLA service 0x2ff4be7a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1741037682.358431 1414855 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
            "2025-03-03 16:34:42.591360: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1741037684.391210 1414855 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step\n"
          ]
        }
      ],
      "source": [
        "#After training model(s)\n",
        "evaluate_model(model, test_ds, 'ResNet152V2')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 1608934,
          "sourceId": 2645886,
          "sourceType": "datasetVersion"
        },
        {
          "modelId": 242991,
          "modelInstanceId": 221210,
          "sourceId": 258804,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30886,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
