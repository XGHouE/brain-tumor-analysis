{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:33:19.210145Z",
          "iopub.status.busy": "2025-03-01T11:33:19.209853Z",
          "iopub.status.idle": "2025-03-01T11:33:19.550165Z",
          "shell.execute_reply": "2025-03-01T11:33:19.549286Z",
          "shell.execute_reply.started": "2025-03-01T11:33:19.210124Z"
        },
        "id": "2lfd1iJcx2YX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import pathlib\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "# There are other models we can use...\n",
        "# from tensorflow.keras.applications import InceptionV3\n",
        "# from tensorflow.keras.applications import EfficientNetV2L\n",
        "# from tensorflow.keras.applications import Xception\n",
        "# from tensorflow.keras.applications import VGG16\n",
        "# from tensorflow.keras.applications import MobileNetV2\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N--n_7q7x2YY"
      },
      "source": [
        "# Dataset paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-01T05:54:47.356113Z",
          "iopub.status.busy": "2025-03-01T05:54:47.355783Z",
          "iopub.status.idle": "2025-03-01T05:54:47.360456Z",
          "shell.execute_reply": "2025-03-01T05:54:47.359517Z",
          "shell.execute_reply.started": "2025-03-01T05:54:47.356084Z"
        },
        "id": "HbkRcHfVx2YZ",
        "outputId": "51b903fb-941b-4f37-db87-27523c447a1a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'brain-tumor-analysis'...\n",
            "remote: Enumerating objects: 7707, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 7707 (delta 14), reused 11 (delta 7), pack-reused 7683 (from 1)\u001b[K\n",
            "Receiving objects: 100% (7707/7707), 92.00 MiB | 23.91 MiB/s, done.\n",
            "Resolving deltas: 100% (3093/3093), done.\n",
            "Updating files: 100% (15284/15284), done.\n",
            "/content/brain-tumor-analysis\n",
            " 30-epoch.ipynb\t\t    'ResNet152v2 Implementation with TF + keras.ipynb'\n",
            "'30-epoch (trained).ipynb'   SegmentationDataset\n",
            " BrainTumorDataset\t     UNetBrainTumorSegmentation.ipynb\n",
            " README.md\n"
          ]
        }
      ],
      "source": [
        "# Dataset paths\n",
        "\n",
        "!git clone https://github.com/XGHouE/brain-tumor-analysis.git\n",
        "%cd brain-tumor-analysis\n",
        "!ls\n",
        "\n",
        "train_dir = pathlib.Path('BrainTumorDataset/Training')\n",
        "test_dir = pathlib.Path('BrainTumorDataset/Testing')\n",
        "\n",
        "img_height = 512\n",
        "img_width = 512\n",
        "batch_size = 16\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pYGXcpJx2YZ"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-01T05:54:49.71085Z",
          "iopub.status.busy": "2025-03-01T05:54:49.710479Z",
          "iopub.status.idle": "2025-03-01T05:54:56.32337Z",
          "shell.execute_reply": "2025-03-01T05:54:56.322727Z",
          "shell.execute_reply.started": "2025-03-01T05:54:49.710821Z"
        },
        "id": "9D1SU9w6x2YZ",
        "outputId": "f06b82b4-bdf4-41da-9e11-d852b5a421e9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2442 files belonging to 4 classes.\n",
            "Using 1954 files for training.\n",
            "Classes in the dataset: ['1', '2', '3', 'notumor']\n",
            "Found 2442 files belonging to 4 classes.\n",
            "Using 488 files for validation.\n",
            "Found 2133 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Dataset loading\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(512, 512),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    interpolation=\"bilinear\",\n",
        "    label_mode=\"int\",\n",
        ")\n",
        "\n",
        "# Get class names\n",
        "class_names = train_ds.class_names\n",
        "print(\"Classes in the dataset:\", class_names)\n",
        "\n",
        "# Normalize and apply data augmentation\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2),\n",
        "    tf.keras.layers.RandomContrast(0.2),\n",
        "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
        "])\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "# Validation dataset\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(512, 512),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Test dataset\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=(512, 512),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BptN1X6Hx2Ya"
      },
      "source": [
        "# Balancing using class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-03-01T05:54:56.32459Z",
          "iopub.status.busy": "2025-03-01T05:54:56.324301Z",
          "iopub.status.idle": "2025-03-01T05:56:07.520039Z",
          "shell.execute_reply": "2025-03-01T05:56:07.519193Z",
          "shell.execute_reply.started": "2025-03-01T05:54:56.324569Z"
        },
        "id": "6E7O9Gdfx2Ya",
        "outputId": "6ebc570e-1625-49d5-a7fb-53694311f8bd",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating class weights...\n"
          ]
        }
      ],
      "source": [
        "def get_class_weights(train_ds, class_names):\n",
        "    print(\"Calculating class weights...\")\n",
        "\n",
        "    labels = []\n",
        "    for image_batch, label_batch in train_ds:\n",
        "        labels.append(label_batch.numpy())\n",
        "\n",
        "    labels = np.concatenate(labels)\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "\n",
        "    class_weight_dict = {i: class_weights[i] for i in range(len(class_names))}\n",
        "    print(\"Class weights calculated.\")\n",
        "    return class_weight_dict\n",
        "\n",
        "class_weight_dict = get_class_weights(train_ds, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6MHNg3Ix2Ya"
      },
      "source": [
        "# Create and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:07.521819Z",
          "iopub.status.busy": "2025-03-01T05:56:07.521556Z",
          "iopub.status.idle": "2025-03-01T05:56:07.528904Z",
          "shell.execute_reply": "2025-03-01T05:56:07.527989Z",
          "shell.execute_reply.started": "2025-03-01T05:56:07.521798Z"
        },
        "id": "UyOCDnqbx2Ya",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def create_and_train_model(base_model, model_name, train_ds, val_ds, test_ds, num_classes=4, learning_rate=0.0001, epochs=epochs, class_weight=None):\n",
        "    for layer in base_model.layers[:10]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999),\n",
        "        loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(f\"\\nSummary of {model_name}:\")\n",
        "    model.summary()\n",
        "\n",
        "    model_checkpoint = ModelCheckpoint(f'{model_name}.keras', monitor='val_loss', save_best_only=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        shuffle=True,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs,\n",
        "        class_weight=class_weight,\n",
        "        callbacks=[model_checkpoint, reduce_lr]\n",
        "    )\n",
        "\n",
        "    # End time tracking\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate computation time\n",
        "    computation_time = end_time - start_time\n",
        "\n",
        "    print(f\"Model training took {computation_time:.2f} seconds.\")\n",
        "\n",
        "    print(f\"\\nEvaluating {model_name}...\")\n",
        "    print(f\"\\nClass Weights used in training {model_name}: {class_weight}\")\n",
        "    loss, accuracy = model.evaluate(test_ds)\n",
        "    print('Loss:', loss)\n",
        "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "    model.save(f'{model_name}.keras')\n",
        "    evaluation = model.evaluate(test_ds)\n",
        "\n",
        "    return model, history, evaluation, computation_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:07.530382Z",
          "iopub.status.busy": "2025-03-01T05:56:07.530124Z",
          "iopub.status.idle": "2025-03-01T05:56:07.548298Z",
          "shell.execute_reply": "2025-03-01T05:56:07.547456Z",
          "shell.execute_reply.started": "2025-03-01T05:56:07.530364Z"
        },
        "id": "ZflrHDiwx2Yb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_ds, model_name):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for images, labels in test_ds:\n",
        "        predictions = model.predict(images)\n",
        "        y_pred.extend(np.argmax(predictions, axis=1))\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\nModel Evaluation Metrics for {model_name}:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(4), yticklabels=range(4))\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "    return accuracy, precision, recall, f1, mae, rmse, cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRWiAypxx2Yb"
      },
      "source": [
        "# Train all models with 30 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:07.549456Z",
          "iopub.status.busy": "2025-03-01T05:56:07.549167Z",
          "iopub.status.idle": "2025-03-01T05:56:26.683192Z",
          "shell.execute_reply": "2025-03-01T05:56:26.682279Z",
          "shell.execute_reply.started": "2025-03-01T05:56:07.549435Z"
        },
        "id": "rEczdOccx2Yb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the model(s)\n",
        "base_model3 = ResNet152V2(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n",
        "#base_model1 = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "#base_model2 = EfficientNetV2L(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "#base_model4 = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "#base_model5 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "#base_model6 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:26.684536Z",
          "iopub.status.busy": "2025-03-01T05:56:26.684215Z",
          "iopub.status.idle": "2025-03-01T11:30:19.23131Z",
          "shell.execute_reply": "2025-03-01T11:30:19.230507Z",
          "shell.execute_reply.started": "2025-03-01T05:56:26.684507Z"
        },
        "id": "_2lpTe-7x2Yb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(train_ds)\n",
        "model3, history3, evaluation3, time3 = create_and_train_model(base_model3, 'model3_resnet152v2_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n",
        "# model1, history1, evaluation1, time1 = create_and_train_model(base_model1, 'model1_inceptionv3_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n",
        "# model2, history2, evaluation2, time2 = create_and_train_model(base_model2, 'model2_efficientnetv2l_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n",
        "# model4, history4, evaluation4, time4 = create_and_train_model(base_model4, 'model4_xception_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n",
        "# model5, history5, evaluation5, time5 = create_and_train_model(base_model5, 'model5_vgg16_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n",
        "# model6, history6, evaluation6, time6 = create_and_train_model(base_model6, 'model6_mobilenetv2_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:32:09.737189Z",
          "iopub.status.busy": "2025-03-01T11:32:09.736861Z",
          "iopub.status.idle": "2025-03-01T11:32:10.727907Z",
          "shell.execute_reply": "2025-03-01T11:32:10.726929Z",
          "shell.execute_reply.started": "2025-03-01T11:32:09.737161Z"
        },
        "id": "F-JNT8Rpx2Yb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define model names\n",
        "model_names = [\"ResNet152V2\"]\n",
        "\n",
        "# Store histories in a list\n",
        "histories = [history3]\n",
        "\n",
        "# Plot Training Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['accuracy'], label=f'{model_names[i]} Training')\n",
        "plt.title('Training Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot Validation Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['val_accuracy'], label=f'{model_names[i]} Validation')\n",
        "plt.title('Validation Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot Training Loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['loss'], label=f'{model_names[i]} Training Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot Validation Loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['val_loss'], label=f'{model_names[i]} Validation Loss')\n",
        "plt.title('Validation Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:33:29.97059Z",
          "iopub.status.busy": "2025-03-01T11:33:29.970075Z",
          "iopub.status.idle": "2025-03-01T11:35:24.140369Z",
          "shell.execute_reply": "2025-03-01T11:35:24.139496Z",
          "shell.execute_reply.started": "2025-03-01T11:33:29.970563Z"
        },
        "id": "7yV7nYK0x2Yc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#After training model(s)\n",
        "evaluate_model(model3, test_ds, 'model3_resnet152v2_class_weights')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 1608934,
          "sourceId": 2645886,
          "sourceType": "datasetVersion"
        },
        {
          "modelId": 242991,
          "modelInstanceId": 221210,
          "sourceId": 258804,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30886,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
