{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:33:19.210145Z",
          "iopub.status.busy": "2025-03-01T11:33:19.209853Z",
          "iopub.status.idle": "2025-03-01T11:33:19.550165Z",
          "shell.execute_reply": "2025-03-01T11:33:19.549286Z",
          "shell.execute_reply.started": "2025-03-01T11:33:19.210124Z"
        },
        "trusted": true,
        "id": "2lfd1iJcx2YX"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import pathlib\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "# There are other models we can use...\n",
        "# from tensorflow.keras.applications import InceptionV3\n",
        "# from tensorflow.keras.applications import EfficientNetV2L\n",
        "# from tensorflow.keras.applications import Xception\n",
        "# from tensorflow.keras.applications import VGG16\n",
        "# from tensorflow.keras.applications import MobileNetV2\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N--n_7q7x2YY"
      },
      "source": [
        "# Dataset paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:54:47.356113Z",
          "iopub.status.busy": "2025-03-01T05:54:47.355783Z",
          "iopub.status.idle": "2025-03-01T05:54:47.360456Z",
          "shell.execute_reply": "2025-03-01T05:54:47.359517Z",
          "shell.execute_reply.started": "2025-03-01T05:54:47.356084Z"
        },
        "trusted": true,
        "id": "HbkRcHfVx2YZ",
        "outputId": "51b903fb-941b-4f37-db87-27523c447a1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'brain-tumor-analysis'...\n",
            "remote: Enumerating objects: 7707, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 7707 (delta 14), reused 11 (delta 7), pack-reused 7683 (from 1)\u001b[K\n",
            "Receiving objects: 100% (7707/7707), 92.00 MiB | 23.91 MiB/s, done.\n",
            "Resolving deltas: 100% (3093/3093), done.\n",
            "Updating files: 100% (15284/15284), done.\n",
            "/content/brain-tumor-analysis\n",
            " 30-epoch.ipynb\t\t    'ResNet152v2 Implementation with TF + keras.ipynb'\n",
            "'30-epoch (trained).ipynb'   SegmentationDataset\n",
            " BrainTumorDataset\t     UNetBrainTumorSegmentation.ipynb\n",
            " README.md\n"
          ]
        }
      ],
      "source": [
        "# Dataset paths\n",
        "\n",
        "!git clone https://github.com/XGHouE/brain-tumor-analysis.git\n",
        "%cd brain-tumor-analysis\n",
        "!ls\n",
        "\n",
        "train_dir = pathlib.Path('BrainTumorDataset/Training')\n",
        "test_dir = pathlib.Path('BrainTumorDataset/Testing')\n",
        "\n",
        "img_height = 512\n",
        "img_width = 512\n",
        "batch_size = 16\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pYGXcpJx2YZ"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:54:49.71085Z",
          "iopub.status.busy": "2025-03-01T05:54:49.710479Z",
          "iopub.status.idle": "2025-03-01T05:54:56.32337Z",
          "shell.execute_reply": "2025-03-01T05:54:56.322727Z",
          "shell.execute_reply.started": "2025-03-01T05:54:49.710821Z"
        },
        "trusted": true,
        "id": "9D1SU9w6x2YZ",
        "outputId": "f06b82b4-bdf4-41da-9e11-d852b5a421e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2442 files belonging to 4 classes.\n",
            "Using 1954 files for training.\n",
            "Classes in the dataset: ['1', '2', '3', 'notumor']\n",
            "Found 2442 files belonging to 4 classes.\n",
            "Using 488 files for validation.\n",
            "Found 2133 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Dataset loading\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(512, 512),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    interpolation=\"bilinear\",\n",
        "    label_mode=\"int\",\n",
        ")\n",
        "\n",
        "# Get class names\n",
        "class_names = train_ds.class_names\n",
        "print(\"Classes in the dataset:\", class_names)\n",
        "\n",
        "# Normalize and apply data augmentation\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2),\n",
        "    tf.keras.layers.RandomContrast(0.2),\n",
        "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
        "])\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "# Validation dataset\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(512, 512),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Test dataset\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=(512, 512),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BptN1X6Hx2Ya"
      },
      "source": [
        "# Balancing using class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:54:56.32459Z",
          "iopub.status.busy": "2025-03-01T05:54:56.324301Z",
          "iopub.status.idle": "2025-03-01T05:56:07.520039Z",
          "shell.execute_reply": "2025-03-01T05:56:07.519193Z",
          "shell.execute_reply.started": "2025-03-01T05:54:56.324569Z"
        },
        "trusted": true,
        "id": "6E7O9Gdfx2Ya",
        "outputId": "6ebc570e-1625-49d5-a7fb-53694311f8bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating class weights...\n"
          ]
        }
      ],
      "source": [
        "def get_class_weights(train_ds, class_names):\n",
        "    print(\"Calculating class weights...\")\n",
        "\n",
        "    labels = []\n",
        "    for image_batch, label_batch in train_ds:\n",
        "        labels.append(label_batch.numpy())\n",
        "\n",
        "    labels = np.concatenate(labels)\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "\n",
        "    class_weight_dict = {i: class_weights[i] for i in range(len(class_names))}\n",
        "    print(\"Class weights calculated.\")\n",
        "    return class_weight_dict\n",
        "\n",
        "class_weight_dict = get_class_weights(train_ds, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6MHNg3Ix2Ya"
      },
      "source": [
        "# Create and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:07.521819Z",
          "iopub.status.busy": "2025-03-01T05:56:07.521556Z",
          "iopub.status.idle": "2025-03-01T05:56:07.528904Z",
          "shell.execute_reply": "2025-03-01T05:56:07.527989Z",
          "shell.execute_reply.started": "2025-03-01T05:56:07.521798Z"
        },
        "trusted": true,
        "id": "UyOCDnqbx2Ya"
      },
      "outputs": [],
      "source": [
        "def create_and_train_model(base_model, model_name, train_ds, val_ds, test_ds, num_classes=4, learning_rate=0.0001, epochs=epochs, class_weight=None):\n",
        "    for layer in base_model.layers[:10]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999),\n",
        "        loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(f\"\\nSummary of {model_name}:\")\n",
        "    model.summary()\n",
        "\n",
        "    model_checkpoint = ModelCheckpoint(f'{model_name}.keras', monitor='val_loss', save_best_only=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        shuffle=True,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs,\n",
        "        class_weight=class_weight,\n",
        "        callbacks=[model_checkpoint, reduce_lr]\n",
        "    )\n",
        "\n",
        "    # End time tracking\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate computation time\n",
        "    computation_time = end_time - start_time\n",
        "\n",
        "    print(f\"Model training took {computation_time:.2f} seconds.\")\n",
        "\n",
        "    print(f\"\\nEvaluating {model_name}...\")\n",
        "    print(f\"\\nClass Weights used in training {model_name}: {class_weight}\")\n",
        "    loss, accuracy = model.evaluate(test_ds)\n",
        "    print('Loss:', loss)\n",
        "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "    model.save(f'{model_name}.keras')\n",
        "    evaluation = model.evaluate(test_ds)\n",
        "\n",
        "    return model, history, evaluation, computation_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:07.530382Z",
          "iopub.status.busy": "2025-03-01T05:56:07.530124Z",
          "iopub.status.idle": "2025-03-01T05:56:07.548298Z",
          "shell.execute_reply": "2025-03-01T05:56:07.547456Z",
          "shell.execute_reply.started": "2025-03-01T05:56:07.530364Z"
        },
        "trusted": true,
        "id": "ZflrHDiwx2Yb"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_ds, model_name):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for images, labels in test_ds:\n",
        "        predictions = model.predict(images)\n",
        "        y_pred.extend(np.argmax(predictions, axis=1))\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\nModel Evaluation Metrics for {model_name}:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(4), yticklabels=range(4))\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "    return accuracy, precision, recall, f1, mae, rmse, cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRWiAypxx2Yb"
      },
      "source": [
        "# Train all models with 30 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:07.549456Z",
          "iopub.status.busy": "2025-03-01T05:56:07.549167Z",
          "iopub.status.idle": "2025-03-01T05:56:26.683192Z",
          "shell.execute_reply": "2025-03-01T05:56:26.682279Z",
          "shell.execute_reply.started": "2025-03-01T05:56:07.549435Z"
        },
        "trusted": true,
        "id": "rEczdOccx2Yb"
      },
      "outputs": [],
      "source": [
        "# Define the model(s)\n",
        "base_model3 = ResNet152V2(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n",
        "#base_model1 = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "#base_model2 = EfficientNetV2L(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "#base_model4 = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "#base_model5 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "#base_model6 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T05:56:26.684536Z",
          "iopub.status.busy": "2025-03-01T05:56:26.684215Z",
          "iopub.status.idle": "2025-03-01T11:30:19.23131Z",
          "shell.execute_reply": "2025-03-01T11:30:19.230507Z",
          "shell.execute_reply.started": "2025-03-01T05:56:26.684507Z"
        },
        "trusted": true,
        "id": "_2lpTe-7x2Yb"
      },
      "outputs": [],
      "source": [
        "print(train_ds)\n",
        "model3, history3, evaluation3, time3 = create_and_train_model(base_model3, 'model3_resnet152v2_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n",
        "# model1, history1, evaluation1, time1 = create_and_train_model(base_model1, 'model1_inceptionv3_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n",
        "# model2, history2, evaluation2, time2 = create_and_train_model(base_model2, 'model2_efficientnetv2l_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n",
        "# model4, history4, evaluation4, time4 = create_and_train_model(base_model4, 'model4_xception_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n",
        "# model5, history5, evaluation5, time5 = create_and_train_model(base_model5, 'model5_vgg16_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)\n",
        "# model6, history6, evaluation6, time6 = create_and_train_model(base_model6, 'model6_mobilenetv2_class_weights', train_ds, val_ds, test_ds, epochs=epochs, class_weight=class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:32:09.737189Z",
          "iopub.status.busy": "2025-03-01T11:32:09.736861Z",
          "iopub.status.idle": "2025-03-01T11:32:10.727907Z",
          "shell.execute_reply": "2025-03-01T11:32:10.726929Z",
          "shell.execute_reply.started": "2025-03-01T11:32:09.737161Z"
        },
        "trusted": true,
        "id": "F-JNT8Rpx2Yb"
      },
      "outputs": [],
      "source": [
        "# Define model names\n",
        "model_names = [\"ResNet152V2\"]\n",
        "\n",
        "# Store histories in a list\n",
        "histories = [history3]\n",
        "\n",
        "# Plot Training Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['accuracy'], label=f'{model_names[i]} Training')\n",
        "plt.title('Training Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot Validation Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['val_accuracy'], label=f'{model_names[i]} Validation')\n",
        "plt.title('Validation Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot Training Loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['loss'], label=f'{model_names[i]} Training Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot Validation Loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['val_loss'], label=f'{model_names[i]} Validation Loss')\n",
        "plt.title('Validation Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:33:29.97059Z",
          "iopub.status.busy": "2025-03-01T11:33:29.970075Z",
          "iopub.status.idle": "2025-03-01T11:35:24.140369Z",
          "shell.execute_reply": "2025-03-01T11:35:24.139496Z",
          "shell.execute_reply.started": "2025-03-01T11:33:29.970563Z"
        },
        "trusted": true,
        "id": "7yV7nYK0x2Yc"
      },
      "outputs": [],
      "source": [
        "# # After training model(s)\n",
        "evaluate_model(model3, test_ds, 'model3_resnet152v2_class_weights')\n",
        "# evaluate_model(model1, test_ds, 'model1_inceptionv3_class_weights')\n",
        "# evaluate_model(model2, test_ds, 'model2_efficientnetv2l_class_weights')\n",
        "# evaluate_model(model4, test_ds, 'model4_xception_class_weights')\n",
        "# evaluate_model(model5, test_ds, 'model5_vgg16_class_weights')\n",
        "# evaluate_model(model6, test_ds, 'model6_mobilenetv2_class_weights')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDssl1l9x2Yc"
      },
      "source": [
        "# Load models (STOP, Below is still in construction...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:43:33.999043Z",
          "iopub.status.busy": "2025-03-01T11:43:33.998679Z",
          "iopub.status.idle": "2025-03-01T11:44:12.116541Z",
          "shell.execute_reply": "2025-03-01T11:44:12.115756Z",
          "shell.execute_reply.started": "2025-03-01T11:43:33.999018Z"
        },
        "trusted": true,
        "id": "GLat_dMQx2Yc"
      },
      "outputs": [],
      "source": [
        "model1 = load_model('/kaggle/working/model1_inceptionv3_class_weights.keras')\n",
        "model2 = load_model('/kaggle/working/model2_efficientnetv2l_class_weights.keras')\n",
        "model3 = load_model('/kaggle/working/model3_resnet152v2_class_weights.keras')\n",
        "model4 = load_model('/kaggle/working/model4_xception_class_weights.keras')\n",
        "model5 = load_model('/kaggle/working/model5_vgg16_class_weights.keras')\n",
        "model6 = load_model('/kaggle/working/model6_mobilenetv2_class_weights.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:44:12.11831Z",
          "iopub.status.busy": "2025-03-01T11:44:12.117968Z",
          "iopub.status.idle": "2025-03-01T11:44:12.12247Z",
          "shell.execute_reply": "2025-03-01T11:44:12.121729Z",
          "shell.execute_reply.started": "2025-03-01T11:44:12.118274Z"
        },
        "trusted": true,
        "id": "zB-epV3Fx2Yc"
      },
      "outputs": [],
      "source": [
        "# Define ensembles\n",
        "ensemble1 = [model2, model4, model3]\n",
        "ensemble2 = [model1, model2, model4]\n",
        "ensemble3 = [model2, model3, model6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:45:30.038052Z",
          "iopub.status.busy": "2025-03-01T11:45:30.037756Z",
          "iopub.status.idle": "2025-03-01T11:45:30.042958Z",
          "shell.execute_reply": "2025-03-01T11:45:30.042053Z",
          "shell.execute_reply.started": "2025-03-01T11:45:30.038031Z"
        },
        "trusted": true,
        "id": "V34G9MHfx2Yc"
      },
      "outputs": [],
      "source": [
        "def ensemble_predict(models, test_ds):\n",
        "    all_predictions = []\n",
        "    y_true = []\n",
        "\n",
        "    for images, labels in test_ds:\n",
        "        y_true.extend(labels.numpy())\n",
        "        preds = [model.predict(images, verbose=0) for model in models]\n",
        "        all_predictions.append(np.mean(preds, axis=0))\n",
        "\n",
        "    avg_predictions = np.vstack(all_predictions)\n",
        "    final_predictions = np.argmax(avg_predictions, axis=1)\n",
        "    return np.array(y_true), final_predictions, avg_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-01T11:45:32.573793Z",
          "iopub.status.busy": "2025-03-01T11:45:32.573478Z",
          "iopub.status.idle": "2025-03-01T11:45:32.58127Z",
          "shell.execute_reply": "2025-03-01T11:45:32.580445Z",
          "shell.execute_reply.started": "2025-03-01T11:45:32.573768Z"
        },
        "trusted": true,
        "id": "l-j6nkCJx2Yc"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate ensemble and save results\n",
        "def evaluate_and_save_ensemble(models, test_ds, model_name):\n",
        "    y_true, y_pred, avg_probs = ensemble_predict(models, test_ds)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sensitivity = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
        "    specificity = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
        "\n",
        "    # Additional metrics\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(f\"\\n=== Model Evaluation Metrics for {model_name} ===\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Sensitivity: {sensitivity:.4f}\")\n",
        "    print(f\"Specificity: {specificity:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "    # Save results\n",
        "    with open(f'{model_name}_results.pkl', 'wb') as f:\n",
        "        pickle.dump({'y_true': y_true, 'y_pred': y_pred, 'avg_probs': avg_probs}, f)\n",
        "\n",
        "    print(f\"Ensemble '{model_name}' results saved successfully!\")\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(4), yticklabels=range(4))\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-01T11:45:36.594234Z",
          "iopub.status.busy": "2025-03-01T11:45:36.593945Z",
          "iopub.status.idle": "2025-03-01T11:48:16.207336Z",
          "shell.execute_reply": "2025-03-01T11:48:16.206624Z",
          "shell.execute_reply.started": "2025-03-01T11:45:36.594211Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "FeHNa1vbx2Yc"
      },
      "outputs": [],
      "source": [
        "# Run evaluation for all ensembles\n",
        "evaluate_and_save_ensemble(ensemble1, test_ds, \"ensemble1\")\n",
        "evaluate_and_save_ensemble(ensemble2, test_ds, \"ensemble2\")\n",
        "evaluate_and_save_ensemble(ensemble3, test_ds, \"ensemble3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-28T14:40:16.349501Z",
          "iopub.status.busy": "2025-02-28T14:40:16.349149Z",
          "iopub.status.idle": "2025-02-28T14:40:16.850661Z",
          "shell.execute_reply": "2025-02-28T14:40:16.849924Z",
          "shell.execute_reply.started": "2025-02-28T14:40:16.349471Z"
        },
        "trusted": true,
        "id": "Of3-qFRQx2Yc"
      },
      "outputs": [],
      "source": [
        "ensembles = [\"Ensemble 1\", \"Ensemble 2\", \"Ensemble 3\"]\n",
        "accuracy = [0.9947, 0.9924, 0.9908]\n",
        "precision = [0.9945, 0.9920, 0.9904]\n",
        "recall = [0.9946, 0.9921, 0.9905]\n",
        "f1_score = [0.9945, 0.9921, 0.9904]\n",
        "sensitivity = [0.9946, 0.9921, 0.9905]\n",
        "specificity = [0.9945, 0.9920, 0.9904]\n",
        "mae = [0.0076, 0.0137, 0.0130]\n",
        "rmse = [0.1172, 0.1747, 0.1487]\n",
        "\n",
        "\n",
        "colors = [\"#203f85\", \"#1eb4cb\", \"#fdf6de\", \"#f03c29\", \"#fbd022\"]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(ensembles, accuracy, color=colors[1])\n",
        "plt.xlabel(\"Ensemble Models\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Comparison of Ensemble Models\")\n",
        "plt.ylim(0.98, 1.0)\n",
        "for i, v in enumerate(accuracy):\n",
        "    plt.text(i, v, f\"{v:.4f}\", ha='center', va='bottom', fontsize=12, color='black')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "metrics = [precision, recall, f1_score]\n",
        "labels = [\"Precision\", \"Recall\", \"F1 Score\"]\n",
        "metric_colors = [colors[0], colors[3], colors[4]]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "bar_width = 0.25\n",
        "x = np.arange(len(ensembles))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    plt.bar(x + i * bar_width, metric, width=bar_width, label=labels[i], color=metric_colors[i])\n",
        "\n",
        "plt.xlabel(\"Ensemble Models\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Precision, Recall, and F1 Score Comparison\")\n",
        "plt.xticks(x + bar_width, ensembles)\n",
        "plt.legend()\n",
        "plt.ylim(0.98, 1.0)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "bar_width = 0.25\n",
        "x = np.arange(len(ensembles))\n",
        "\n",
        "plt.bar(x, mae, width=bar_width, label=\"MAE\", color=colors[3])\n",
        "plt.bar(x + bar_width, rmse, width=bar_width, label=\"RMSE\", color=colors[1])\n",
        "\n",
        "plt.xlabel(\"Ensemble Models\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.title(\"MAE and RMSE Comparison\")\n",
        "plt.xticks(x + bar_width / 2, ensembles)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 1608934,
          "sourceId": 2645886,
          "sourceType": "datasetVersion"
        },
        {
          "modelId": 242991,
          "modelInstanceId": 221210,
          "sourceId": 258804,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30886,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}